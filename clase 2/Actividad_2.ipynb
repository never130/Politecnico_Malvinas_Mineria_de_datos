{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f1ece2c",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/never130/Politecnico_Malvinas_Mineria_de_datos/blob/main/clase%202/Actividad_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drW1I2QggUsr",
   "metadata": {
    "id": "drW1I2QggUsr"
   },
   "source": [
    "# <font color='yellow'>Exploración y Limpieza de Datos en Práctica</font>\n",
    "\n",
    "### Objetivo de la Actividad:\n",
    "\n",
    "En esta actividad, aplicarás los conceptos de limpieza y preprocesamiento de datos en un conjunto de datos real. Usarás herramientas de inteligencia artificial como ChatGPT o Google Gemini para investigar y aplicar técnicas de limpieza de datos. Cada estudiante deberá elegir un aspecto diferente de la limpieza de datos para explorar y compartir sus hallazgos y aplicaciones en el foro de la clase.\n",
    "\n",
    "### Instrucciones:\n",
    "1. **Selección del Aspecto de Limpieza de Datos:** Selecciona uno de\n",
    "los siguientes aspectos de la limpieza de datos sobre los que quieras\n",
    "aprender más y aplicar en un conjunto de datos real:\n",
    "- Tratamiento de datos faltantes.\n",
    "- Detección y manejo de datos atípicos.\n",
    "- Transformación de variables para normalización.\n",
    "- Codificación de variables categóricas.\n",
    "- Eliminación de duplicados.\n",
    "2. **Investigación**: Utiliza ChatGPT o Google Gemini para investigar el aspecto seleccionado. Busca técnicas, mejores prácticas, y ejemplos de código que se aplican a este aspecto de la limpieza de datos. Intenta comprender no solo cómo se aplican estas técnicas, sino también cuándo y por qué se utilizan.\n",
    "3. **Aplicación Práctica:** Elige un conjunto de datos público de\n",
    "plataformas como Kaggle, UCI Machine Learning Repository, o\n",
    "cualquier otro repositorio de datos abiertos. Aplica las técnicas de\n",
    "limpieza de datos que has investigado al conjunto de datos\n",
    "seleccionado utilizando Python y Pandas.\n",
    "Nota: Asegúrate de documentar tu proceso, incluyendo:\n",
    "- La selección y descripción breve del conjunto de datos.\n",
    "- El código utilizado para aplicar las técnicas de limpieza.\n",
    "- Antes y después de la limpieza: Observaciones sobre cómo ha\n",
    "cambiado el conjunto de datos y el impacto en el análisis.\n",
    "4. **Compartir y Discutir en el Foro**: Publica tus hallazgos, tu proceso,\n",
    "y tu código en el foro de la clase. Tu publicación debe incluir:\n",
    "- Una breve introducción al aspecto de limpieza de datos que\n",
    "investigaste.\n",
    "- Un resumen de tus hallazgos y la técnica que aplicaste.\n",
    "- Cómo crees que la aplicación de esta técnica mejora el análisis\n",
    "de datos.\n",
    "5. **Revisión por Pares**: Lee y comenta al menos dos publicaciones de tus compañeros en el foro. Ofrece retroalimentación, plantea\n",
    "preguntas, o sugiere otras maneras en que las técnicas de limpieza\n",
    "podrían aplicarse al conjunto de datos que han trabajado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64a957a-af53-4a2f-807d-b236d7ff1c52",
   "metadata": {
    "id": "a64a957a-af53-4a2f-807d-b236d7ff1c52"
   },
   "source": [
    "### <font color = 'yellow'>**1. Tratamiento de datos faltantes**\n",
    "Es una técnica clave en el análisis de datos.\n",
    "Este aspecto es crucial cuando se trabaja con datasets reales, ya que la mayoría de ellos presentan valores faltantes que pueden afectar el análisis y los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55503131-39fa-4d47-8863-1df421dc6e1c",
   "metadata": {
    "id": "55503131-39fa-4d47-8863-1df421dc6e1c",
    "outputId": "1a61bc60-5c9c-4b21-8656-76de226ac4dd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame con valores faltantes:\n",
      "    columna_1  columna_2  columna_3\n",
      "0       10.0        NaN        5.0\n",
      "1       20.0        1.5        NaN\n",
      "2        NaN        2.5        NaN\n",
      "3       40.0        NaN       20.0\n",
      "4       50.0        4.5       25.0 \n",
      "\n",
      "1. Filas con valores faltantes eliminadas... \n",
      "    columna_1  columna_2  columna_3\n",
      "4       50.0        4.5       25.0 \n",
      "\n",
      "2. Columnas con valores faltantes eliminadas:\n",
      " Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0, 1, 2, 3, 4] \n",
      "\n",
      "3. Valores faltantes reemplazados por un valor constante (0):\n",
      "    columna_1  columna_2  columna_3\n",
      "0       10.0        0.0        5.0\n",
      "1       20.0        1.5        0.0\n",
      "2        0.0        2.5        0.0\n",
      "3       40.0        0.0       20.0\n",
      "4       50.0        4.5       25.0 \n",
      "\n",
      "4. Valores faltantes reemplazados por la media de cada columna:\n",
      "    columna_1  columna_2  columna_3\n",
      "0       10.0   2.833333   5.000000\n",
      "1       20.0   1.500000  16.666667\n",
      "2       30.0   2.500000  16.666667\n",
      "3       40.0   2.833333  20.000000\n",
      "4       50.0   4.500000  25.000000 \n",
      "\n",
      "5. Valores faltantes rellenados con interpolación lineal:\n",
      "    columna_1  columna_2  columna_3\n",
      "0       10.0        NaN        5.0\n",
      "1       20.0        1.5       10.0\n",
      "2       30.0        2.5       15.0\n",
      "3       40.0        3.5       20.0\n",
      "4       50.0        4.5       25.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Crear un DataFrame de ejemplo con algunos valores faltantes\n",
    "data = {'columna_1': [10, 20, np.nan, 40, 50],\n",
    "        'columna_2': [np.nan, 1.5, 2.5, np.nan, 4.5],\n",
    "        'columna_3': [5, np.nan, np.nan, 20, 25]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 1. Eliminar filas con valores faltantes\n",
    "df_sin_nan_filas = df.dropna()\n",
    "\n",
    "# 2. Eliminar columnas con valores faltantes\n",
    "df_sin_nan_columnas = df.dropna(axis=1)\n",
    "\n",
    "# 3. Rellenar valores faltantes con un valor constante (por ejemplo, 0)\n",
    "df_rellenado_constante = df.fillna(0)\n",
    "\n",
    "# 4. Rellenar valores faltantes con la media de cada columna\n",
    "df_rellenado_media = df.apply(lambda x: x.fillna(x.mean()), axis=0)\n",
    "\n",
    "# 5. Rellenar valores faltantes con la interpolación (útil en series temporales)\n",
    "df_interpolado = df.interpolate(method='linear')\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Original DataFrame con valores faltantes:\\n\", df, \"\\n\")\n",
    "print(\"1. Filas con valores faltantes eliminadas... \\n\", df_sin_nan_filas, \"\\n\")\n",
    "print(\"2. Columnas con valores faltantes eliminadas:\\n\", df_sin_nan_columnas, \"\\n\")\n",
    "print(\"3. Valores faltantes reemplazados por un valor constante (0):\\n\", df_rellenado_constante, \"\\n\")\n",
    "print(\"4. Valores faltantes reemplazados por la media de cada columna:\\n\", df_rellenado_media, \"\\n\")\n",
    "print(\"5. Valores faltantes rellenados con interpolación lineal:\\n\", df_interpolado)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7501a7ec-837d-47a2-949e-40186e12d9cb",
   "metadata": {
    "id": "7501a7ec-837d-47a2-949e-40186e12d9cb"
   },
   "source": [
    "### <font color = yellow>**2. Investigacion**\n",
    "#### <font color = 'orange'>1. Eliminación de valores faltantes\n",
    "Cuándo usarlo: Cuando la cantidad de datos faltantes es mínima o no afecta significativamente el análisis. Ideal si los datos son suficientes para proporcionar un resultado válido sin la necesidad de esos registros.\n",
    "\n",
    "Por qué usarlo: Eliminar filas o columnas con datos faltantes puede simplificar el análisis y evitar sesgos en los resultados.\n",
    "\n",
    "Ejemplo de código:<br>\n",
    "<code>df_sin_nan = df.dropna()  # Eliminar filas con al menos un NaN</code>\n",
    "#### <font color = 'orange'>2. Relleno con valores constantes\n",
    "Cuándo usarlo: Cuando un valor específico tiene sentido en el contexto del análisis (por ejemplo, 0 en un conteo).\n",
    "\n",
    "Por qué usarlo: Puede ser útil en análisis donde se desea indicar que no hubo un valor específico.\n",
    "\n",
    "Ejemplo de código:<br/>\n",
    "<code>df.fillna(0, inplace=True)  # Rellenar NaN con 0</code>\n",
    "#### <font color = 'orange'>3. Relleno con la media/mediana/moda\n",
    "Cuándo usarlo: Útil para variables numéricas cuando se desea preservar la media del conjunto de datos.\n",
    "\n",
    "Por qué usarlo: Rellenar con la media o mediana es común en datasets donde los valores faltantes son aleatorios y no tienen un patrón. Rellenar con la moda es útil para variables categóricas.\n",
    "\n",
    "Ejemplo de código:<br>\n",
    "<code>df['columna_1'].fillna(df['columna_1'].mean(), inplace=True)  # Rellenar con la media</code>\n",
    "#### <font color = 'orange'>4. Interpolación\n",
    "Cuándo usarlo: Cuando hay un orden lógico en los datos (como series temporales) y se espera que los valores sigan una tendencia.\n",
    "\n",
    "Por qué usarlo: La interpolación proporciona una estimación más precisa al considerar la relación entre los datos.\n",
    "\n",
    "Ejemplo de código: </br>\n",
    "<code>df.interpolate(method='linear', inplace=True)  # Interpolación lineal</code>\n",
    "#### <font color = 'orange'>5. Imputación basada en modelos</font>\n",
    "Cuándo usarlo: Cuando hay una relación compleja entre las variables, y se puede usar un modelo predictivo para estimar los valores faltantes.\n",
    "\n",
    "Por qué usarlo: Proporciona una forma más robusta de rellenar datos faltantes al modelar las relaciones entre las variables.\n",
    "\n",
    "Ejemplo de código (usando scikit-learn):<br>\n",
    "<pre>from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')  # Usar la media\n",
    "df[['columna_1']] = imputer.fit_transform(df[['columna_1']])\n",
    "</pre>\n",
    "#### <font color = 'orange'>6. Manejo de valores faltantes en variables categóricas\n",
    "Cuándo usarlo: Cuando se trabaja con datos categóricos, es útil rellenar los valores faltantes con la moda.\n",
    "\n",
    "Por qué usarlo: Mantiene la integridad del conjunto de datos sin introducir sesgos.\n",
    "\n",
    "Ejemplo de código:\n",
    "<pre>df['columna_categorica'].fillna(df['columna_categorica'].mode()[0], inplace=True)  # Rellenar con la moda\n",
    "</pre>\n",
    "### Conclusión\n",
    "El tratamiento de datos faltantes es fundamental para garantizar la calidad de los datos antes de realizar cualquier análisis. Las técnicas seleccionadas deben alinearse con la naturaleza de los datos y el objetivo del análisis. Siempre es importante realizar un análisis previo para entender cómo se distribuyen los datos faltantes y qué métodos serán más apropiados para el caso específico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0173f41-6aa9-4bb2-82c0-f5d1d10b17ba",
   "metadata": {
    "id": "a0173f41-6aa9-4bb2-82c0-f5d1d10b17ba"
   },
   "source": [
    "##  <font color = 'Yellow'>3) Aplicación Prácticas\n",
    "#### <font color = 'orange'>Descripción del Conjunto de Datos Titanic\n",
    "- Características: Incluye atributos como Survived (sobrevivió o no), Pclass (clase del pasajero), Name, Sex, Age, SibSp (hermanos/cónyuges a bordo), Parch (padres/hijos a bordo), Ticket, Fare (tarifa), Cabin y Embarked (puerto de embarque).\n",
    "- Objetivo: Aplicar técnicas de limpieza de datos, como tratamiento de valores faltantes y eliminación de duplicados.\n",
    "\n",
    "#### <font color = 'orange'>Pasos para la Limpieza de Datos\n",
    "- Descargar el conjunto de datos.\n",
    "- Código para la limpieza de datos: Aquí hay un ejemplo de cómo podrías cargar y limpiar el conjunto de datos Titanic utilizando Python y Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b8c162-8ab0-4159-87e3-4af6cb978ced",
   "metadata": {
    "id": "88b8c162-8ab0-4159-87e3-4af6cb978ced",
    "outputId": "0a59dc20-c379-46ad-a136-3e85626af0c5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras filas del conjunto de datos:\n",
      "    Passengerid   Age     Fare  Sex  sibsp  zero  zero.1  zero.2  zero.3  \\\n",
      "0            1  22.0   7.2500    0      1     0       0       0       0   \n",
      "1            2  38.0  71.2833    1      1     0       0       0       0   \n",
      "2            3  26.0   7.9250    1      0     0       0       0       0   \n",
      "3            4  35.0  53.1000    1      1     0       0       0       0   \n",
      "4            5  35.0   8.0500    0      0     0       0       0       0   \n",
      "\n",
      "   zero.4  ...  zero.12  zero.13  zero.14  Pclass  zero.15  zero.16  Embarked  \\\n",
      "0       0  ...        0        0        0       3        0        0       2.0   \n",
      "1       0  ...        0        0        0       1        0        0       0.0   \n",
      "2       0  ...        0        0        0       3        0        0       2.0   \n",
      "3       0  ...        0        0        0       1        0        0       2.0   \n",
      "4       0  ...        0        0        0       3        0        0       2.0   \n",
      "\n",
      "   zero.17  zero.18  Survived  \n",
      "0        0        0         0  \n",
      "1        0        0         1  \n",
      "2        0        0         1  \n",
      "3        0        0         1  \n",
      "4        0        0         0  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "\n",
      "Valores faltantes en cada columna:\n",
      " Passengerid    0\n",
      "Age            0\n",
      "Fare           0\n",
      "Sex            0\n",
      "sibsp          0\n",
      "zero           0\n",
      "zero.1         0\n",
      "zero.2         0\n",
      "zero.3         0\n",
      "zero.4         0\n",
      "zero.5         0\n",
      "zero.6         0\n",
      "Parch          0\n",
      "zero.7         0\n",
      "zero.8         0\n",
      "zero.9         0\n",
      "zero.10        0\n",
      "zero.11        0\n",
      "zero.12        0\n",
      "zero.13        0\n",
      "zero.14        0\n",
      "Pclass         0\n",
      "zero.15        0\n",
      "zero.16        0\n",
      "Embarked       2\n",
      "zero.17        0\n",
      "zero.18        0\n",
      "Survived       0\n",
      "dtype: int64\n",
      "\n",
      "Número de filas duplicadas: 0\n",
      "\n",
      "Resumen estadístico:\n",
      "        Passengerid          Age         Fare          Sex        sibsp  \\\n",
      "count  1309.000000  1309.000000  1309.000000  1309.000000  1309.000000   \n",
      "mean    655.000000    29.503186    33.281086     0.355997     0.498854   \n",
      "std     378.020061    12.905241    51.741500     0.478997     1.041658   \n",
      "min       1.000000     0.170000     0.000000     0.000000     0.000000   \n",
      "25%     328.000000    22.000000     7.895800     0.000000     0.000000   \n",
      "50%     655.000000    28.000000    14.454200     0.000000     0.000000   \n",
      "75%     982.000000    35.000000    31.275000     1.000000     1.000000   \n",
      "max    1309.000000    80.000000   512.329200     1.000000     8.000000   \n",
      "\n",
      "         zero  zero.1  zero.2  zero.3  zero.4  ...  zero.12  zero.13  zero.14  \\\n",
      "count  1309.0  1309.0  1309.0  1309.0  1309.0  ...   1309.0   1309.0   1309.0   \n",
      "mean      0.0     0.0     0.0     0.0     0.0  ...      0.0      0.0      0.0   \n",
      "std       0.0     0.0     0.0     0.0     0.0  ...      0.0      0.0      0.0   \n",
      "min       0.0     0.0     0.0     0.0     0.0  ...      0.0      0.0      0.0   \n",
      "25%       0.0     0.0     0.0     0.0     0.0  ...      0.0      0.0      0.0   \n",
      "50%       0.0     0.0     0.0     0.0     0.0  ...      0.0      0.0      0.0   \n",
      "75%       0.0     0.0     0.0     0.0     0.0  ...      0.0      0.0      0.0   \n",
      "max       0.0     0.0     0.0     0.0     0.0  ...      0.0      0.0      0.0   \n",
      "\n",
      "            Pclass  zero.15  zero.16     Embarked  zero.17  zero.18  \\\n",
      "count  1309.000000   1309.0   1309.0  1307.000000   1309.0   1309.0   \n",
      "mean      2.294882      0.0      0.0     1.492731      0.0      0.0   \n",
      "std       0.837836      0.0      0.0     0.814626      0.0      0.0   \n",
      "min       1.000000      0.0      0.0     0.000000      0.0      0.0   \n",
      "25%       2.000000      0.0      0.0     1.000000      0.0      0.0   \n",
      "50%       3.000000      0.0      0.0     2.000000      0.0      0.0   \n",
      "75%       3.000000      0.0      0.0     2.000000      0.0      0.0   \n",
      "max       3.000000      0.0      0.0     2.000000      0.0      0.0   \n",
      "\n",
      "          Survived  \n",
      "count  1309.000000  \n",
      "mean      0.261268  \n",
      "std       0.439494  \n",
      "min       0.000000  \n",
      "25%       0.000000  \n",
      "50%       0.000000  \n",
      "75%       1.000000  \n",
      "max       1.000000  \n",
      "\n",
      "[8 rows x 28 columns]\n",
      "\n",
      "Cantidad de sobrevivientes y no sobrevivientes:\n",
      " Survived\n",
      "0    967\n",
      "1    342\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el conjunto de datos Titanic desde un archivo CSV\n",
    "# Asegúrate de ajustar la ruta del archivo según donde lo hayas guardado\n",
    "df = pd.read_csv('titanic.csv')\n",
    "\n",
    "# Ver las primeras filas del DataFrame\n",
    "print(\"Primeras filas del conjunto de datos:\\n\", df.head())\n",
    "\n",
    "# 1. Comprobar valores faltantes\n",
    "print(\"\\nValores faltantes en cada columna:\\n\", df.isnull().sum())\n",
    "\n",
    "# 2. Eliminar filas con valores faltantes (si existen)\n",
    "df.dropna(subset=['Age'], inplace=True)  # Eliminar filas donde 'Age' es NaN\n",
    "\n",
    "# 3. Comprobar si hay duplicados\n",
    "duplicados = df.duplicated().sum()\n",
    "print(\"\\nNúmero de filas duplicadas:\", duplicados)\n",
    "\n",
    "# 4. Eliminar duplicados si existen\n",
    "if duplicados > 0:\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    print(\"Duplicados eliminados.\")\n",
    "\n",
    "# 5. Resumen estadístico del DataFrame\n",
    "print(\"\\nResumen estadístico:\\n\", df.describe())\n",
    "\n",
    "# 6. Mostrar la cantidad de sobrevivientes y no sobrevivientes\n",
    "print(\"\\nCantidad de sobrevivientes y no sobrevivientes:\\n\", df['Survived'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8592d4-01d3-4af7-be8b-db98a6bf8060",
   "metadata": {
    "id": "fd8592d4-01d3-4af7-be8b-db98a6bf8060"
   },
   "source": [
    "#### <font color = 'orange'>Explicación del Código:\n",
    "- Carga del conjunto de datos: Utilizamos pd.read_csv() para cargar el conjunto de datos Titanic desde un archivo CSV.\n",
    "- Comprobación de valores faltantes: Usamos isnull().sum() para identificar si hay valores faltantes en el DataFrame.\n",
    "- Eliminación de filas con valores faltantes: En este caso, eliminamos solo las filas donde Age es NaN utilizando dropna().\n",
    "- Detección de duplicados: Usamos duplicated().sum() para verificar si hay filas duplicadas.\n",
    "- Eliminación de duplicados: Si hay duplicados, usamos drop_duplicates() para eliminarlos.\n",
    "- Resumen estadístico: describe() proporciona estadísticas descriptivas del DataFrame.\n",
    "- Cantidad de sobrevivientes: Verificamos cuántos pasajeros sobrevivieron y cuántos no usando value_counts().\n",
    "#### <font color = 'orange'> Después de la Limpieza\n",
    "- Valores Faltantes:\n",
    "Se eliminó cualquier fila con valores faltantes en la columna Age. Esto reduce el tamaño del conjunto de datos, pero mejora la calidad de los análisis al asegurarse de que no haya valores NaN que puedan interferir con los cálculos.\n",
    "Alternativamente, si decides imputar los valores faltantes en lugar de eliminarlos, podrías usar la media o mediana de la columna Age, lo que preservaría más datos.\n",
    "\n",
    "- Duplicados:\n",
    "Cualquier fila duplicada se ha eliminado, lo que significa que ahora cada entrada es única. Esto proporciona una mejor base para realizar análisis y evita la duplicación en las métricas que se calculan.\n",
    "\n",
    "- Datos Consistentes:\n",
    "Después de la limpieza, los nombres de las columnas son consistentes, lo que facilita la manipulación de datos. Ahora puedes usar directamente las columnas para análisis sin preocuparte por errores de sintaxis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eacd649-2325-44b5-8df9-705bc3d01c2e",
   "metadata": {
    "id": "3eacd649-2325-44b5-8df9-705bc3d01c2e"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
